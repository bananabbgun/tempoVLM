#!/usr/bin/env python3
"""
test_adaptive.py - Adaptive Memory Injection æ¸¬è©¦è…³æœ¬
=====================================================

åŠŸèƒ½:
- æ¸¬è©¦è‡ªé©æ‡‰è¨˜æ†¶æ³¨å…¥ç³»çµ±
- ä¸éœ€è¦é çŸ¥é®æ“‹æ™‚é–“é»
- è‡ªå‹•æª¢æ¸¬ç•°å¸¸å¹€ä¸¦æ³¨å…¥è¨˜æ†¶

ä½¿ç”¨æ–¹å¼:
    # ç´”æ¸¬è©¦ï¼ˆä¸åŠ é®æ“‹ï¼Œçœ‹æª¢æ¸¬èƒ½åŠ›ï¼‰
    python test_adaptive.py --scene_dir /path/to/scene
    
    # åŠ å…¥äººå·¥é®æ“‹ä¾†æ¸¬è©¦
    python test_adaptive.py --scene_dir /path/to/scene --add_occlusion
    
    # æŒ‡å®šé®æ“‹ç¯„åœ
    python test_adaptive.py --add_occlusion --occlusion_start 15 --occlusion_end 25
"""

import os
import sys
import glob
import argparse
import numpy as np
import cv2
import json
from PIL import Image
from datetime import datetime

from utils.occlusion_tester import OcclusionTester
from utils.memory_utils import AdaptiveMemoryBuffer


class Logger:
    """åŒæ™‚è¼¸å‡ºåˆ°çµ‚ç«¯å’Œæª”æ¡ˆçš„æ—¥èªŒå™¨ï¼Œæª”æ¡ˆä¿å­˜å®Œæ•´å…§å®¹"""
    
    def __init__(self, log_file=None):
        self.terminal = sys.stdout
        self.log_file = None
        if log_file:
            os.makedirs(os.path.dirname(log_file), exist_ok=True)
            self.log_file = open(log_file, 'w', encoding='utf-8')
    
    def write(self, message):
        self.terminal.write(message)
        if self.log_file:
            self.log_file.write(message)
            self.log_file.flush()
    
    def write_full(self, message):
        """åªå¯«å…¥æª”æ¡ˆï¼Œä¸è¼¸å‡ºåˆ°çµ‚ç«¯ï¼ˆç”¨æ–¼ä¿å­˜å®Œæ•´å…§å®¹ï¼‰"""
        if self.log_file:
            self.log_file.write(message)
            self.log_file.flush()
    
    def write_terminal_only(self, message):
        """åªè¼¸å‡ºåˆ°çµ‚ç«¯ï¼Œä¸å¯«å…¥æª”æ¡ˆ"""
        self.terminal.write(message)
    
    def flush(self):
        self.terminal.flush()
        if self.log_file:
            self.log_file.flush()
    
    def close(self):
        if self.log_file:
            self.log_file.close()


# å…¨åŸŸ logger åƒè€ƒï¼Œç”¨æ–¼åœ¨å‡½æ•¸ä¸­å­˜å–
_current_logger = None

def print_response(label, response, max_terminal_lines=3, line_width=70):
    """
    æ‰“å°å›æ‡‰ï¼Œçµ‚ç«¯æˆªæ–·é¡¯ç¤ºï¼Œæª”æ¡ˆä¿å­˜å®Œæ•´å…§å®¹
    
    Args:
        label: æ¨™ç±¤ï¼ˆå¦‚ "ğŸ¯ GT (åŸåœ–)"ï¼‰
        response: å›æ‡‰æ–‡å­—
        max_terminal_lines: çµ‚ç«¯æœ€å¤šé¡¯ç¤ºå¹¾è¡Œ
        line_width: æ¯è¡Œæœ€å¤§å­—å…ƒæ•¸
    """
    global _current_logger
    
    if not response:
        print(f"           {label}")
        print(f"                 (ç„¡å›æ‡‰)")
        return
    
    # åˆ†å‰²æˆå¤šè¡Œ
    lines = [response[j:j+line_width] for j in range(0, len(response), line_width)]
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦æˆªæ–·ï¼ˆçµ‚ç«¯ï¼‰vs å®Œæ•´é¡¯ç¤ºï¼ˆæª”æ¡ˆï¼‰
    need_truncate = len(lines) > max_terminal_lines
    
    if _current_logger and _current_logger.log_file and need_truncate:
        # æœ‰ logger ä¸”éœ€è¦æˆªæ–·ï¼šçµ‚ç«¯æˆªæ–·ï¼Œæª”æ¡ˆå®Œæ•´
        
        # çµ‚ç«¯åªé¡¯ç¤ºæˆªæ–·ç‰ˆæœ¬
        _current_logger.write_terminal_only(f"           {label}\n")
        for line in lines[:max_terminal_lines]:
            _current_logger.write_terminal_only(f"                 {line}\n")
        _current_logger.write_terminal_only(f"                 ... (å…± {len(lines)} è¡Œï¼Œå®Œæ•´å…§å®¹è¦‹æ—¥èªŒæª”æ¡ˆ)\n")
        
        # æª”æ¡ˆç›´æ¥é¡¯ç¤ºå®Œæ•´å…§å®¹
        _current_logger.write_full(f"           {label}\n")
        for line in lines:
            _current_logger.write_full(f"                 {line}\n")
    else:
        # ä¸éœ€è¦æˆªæ–·ï¼Œæˆ–æ²’æœ‰ loggerï¼šæ­£å¸¸è¼¸å‡ºå…¨éƒ¨
        print(f"           {label}")
        for line in lines:
            print(f"                 {line}")


def setup_logging(args):
    """è¨­å®šæ—¥èªŒè¨˜éŒ„"""
    global _current_logger
    
    # å»ºç«‹ logs è³‡æ–™å¤¾
    log_dir = 'logs'
    os.makedirs(log_dir, exist_ok=True)
    
    # ç”Ÿæˆæ—¥èªŒæª”æ¡ˆåç¨±
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # å¾è¼¸å…¥è·¯å¾‘æå–åç¨±
    input_name = 'unknown'
    input_path = args.video or args.scene_dir
    if input_path:
        input_name = os.path.basename(input_path.rstrip('/'))
        # ç§»é™¤å‰¯æª”å
        if '.' in input_name:
            input_name = os.path.splitext(input_name)[0]
    
    # çµ„åˆæª”æ¡ˆåç¨±
    occ_str = f"_occ{args.occlusion_start}-{args.occlusion_end}" if args.add_occlusion else "_no_occ"
    log_filename = f"{timestamp}_{input_name}{occ_str}_{args.injection_method}.log"
    log_path = os.path.join(log_dir, log_filename)
    
    # è¨­å®š Logger
    logger = Logger(log_path)
    sys.stdout = logger
    _current_logger = logger  # è¨­å®šå…¨åŸŸåƒè€ƒ
    
    print(f"ğŸ“ æ—¥èªŒæª”æ¡ˆ: {log_path}")
    
    return logger, log_path


def save_experiment_summary(log_dir, log_path, args, results, final_status):
    """ä¿å­˜å¯¦é©—æ‘˜è¦ç‚º JSON"""
    summary = {
        'timestamp': datetime.now().isoformat(),
        'log_file': log_path,
        'config': {
            'input': args.video or args.scene_dir,
            'add_occlusion': args.add_occlusion,
            'occlusion_start': args.occlusion_start,
            'occlusion_end': args.occlusion_end,
            'occlusion_ratio': args.occlusion_ratio,
            'occlusion_type': args.occlusion_type,
            'injection_method': args.injection_method,
            'memory_size': args.memory_size,
            'max_frames': args.max_frames,
        },
        'results': {
            'total_frames': len(results),
            'anomalies_detected': len([r for r in results if r['is_anomaly']]),
            'successful_injections': len([r for r in results if r['injection'] and 'response' in r.get('injection', {})]),
            'memory_buffer_size': final_status['size'],
        },
        'frames': []
    }
    
    # åŠ å…¥æ¯å¹€çš„è©³ç´°è³‡è¨Š
    for r in results:
        frame_info = {
            'frame': r['frame'],
            'quality': r['quality'],
            'anomaly_score': r['anomaly_score'],
            'image_occlusion': r['image_occlusion'],
            'is_anomaly': r['is_anomaly'],
            'artificial_occlusion': r['artificial'],
        }
        if r['injection']:
            frame_info['injection'] = {
                'strength': r['injection'].get('strength'),
                'memory_frame': r['injection'].get('memory_frame'),
                'scene_match': r['injection'].get('scene_match'),
                'response': r['injection'].get('response', '')[:200],  # æˆªæ–·
                'gt_response': r['injection'].get('gt_response', '')[:200],
                'occluded_response': r['injection'].get('occluded_response', '')[:200],
            }
        summary['frames'].append(frame_info)
    
    # è¨ˆç®—æª¢æ¸¬çµ±è¨ˆ
    if args.add_occlusion:
        artificial = [r for r in results if r['artificial']]
        detected = [r for r in artificial if r['is_anomaly']]
        non_occluded = [r for r in results if not r['artificial']]
        false_positives = [r for r in non_occluded if r['is_anomaly']]
        
        summary['detection_stats'] = {
            'artificial_occlusion_frames': len(artificial),
            'correctly_detected': len(detected),
            'detection_rate': len(detected) / max(len(artificial), 1),
            'false_positives': len(false_positives),
            'false_positive_rate': len(false_positives) / max(len(non_occluded), 1),
        }
    
    # ä¿å­˜ JSON
    json_path = log_path.replace('.log', '.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“Š å¯¦é©—æ‘˜è¦å·²ä¿å­˜: {json_path}")
    
    return json_path


def find_model_path():
    """å°‹æ‰¾æ¨¡å‹è·¯å¾‘"""
    possible_paths = [
        'checkpoints_unified/best_unified_model.pt',
        'checkpoints/unified_model_best.pth',
        'best_unified_model.pt',
    ]
    for p in possible_paths:
        if os.path.exists(p):
            return p
    return None


def find_scene_dir():
    """å°‹æ‰¾å ´æ™¯ç›®éŒ„"""
    possible_dirs = [
        'data/scannet/scene0011_00',
        'scannet_data/scannet_frames_test/scene0011_00',
        'scannet_data/scannet_frames_25k/scene0011_00',
    ]
    for d in possible_dirs:
        if os.path.exists(d):
            return d
    return None


def find_best_scene(data_root, split='test', min_frames=30):
    """
    å°‹æ‰¾ frame æ•¸æœ€å¤šçš„å ´æ™¯
    
    Args:
        data_root: è³‡æ–™æ ¹ç›®éŒ„
        split: 'test' æˆ– 'train'
        min_frames: æœ€å°‘éœ€è¦çš„ frame æ•¸
    
    Returns:
        æœ€ä½³å ´æ™¯çš„è·¯å¾‘ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› None
    """
    from pathlib import Path
    
    data_root = Path(data_root)
    
    if split == 'test':
        scene_root = data_root / 'scannet_frames_test'
    elif split == 'train':
        scene_root = data_root / 'scannet_frames_25k'
    else:
        scene_root = data_root
    
    if not scene_root.exists():
        print(f"âŒ ç›®éŒ„ä¸å­˜åœ¨: {scene_root}")
        return None
    
    all_scene_dirs = [d for d in scene_root.iterdir() if d.is_dir()]
    
    if not all_scene_dirs:
        print(f"âŒ æ‰¾ä¸åˆ°å ´æ™¯: {scene_root}")
        return None
    
    # è¨ˆç®—æ¯å€‹å ´æ™¯çš„ frame æ•¸é‡
    print(f"\nğŸ“Š åˆ†æ {len(all_scene_dirs)} å€‹å ´æ™¯çš„ frame æ•¸é‡...")
    scene_frame_counts = []
    for scene_dir in all_scene_dirs:
        color_dir = scene_dir / 'color'
        if color_dir.exists():
            frame_count = len(list(color_dir.glob('*.jpg')))
        else:
            frame_count = len(list(scene_dir.glob('*.jpg'))) + len(list(scene_dir.glob('*.png')))
        
        if frame_count >= min_frames:
            scene_frame_counts.append((scene_dir, frame_count))
    
    if not scene_frame_counts:
        print(f"âŒ æ²’æœ‰å ´æ™¯æœ‰è¶³å¤ çš„ frame (æœ€å°‘éœ€è¦ {min_frames})")
        return None
    
    # æŒ‰ frame æ•¸é‡é™åºæ’åº
    scene_frame_counts.sort(key=lambda x: x[1], reverse=True)
    
    best_scene, best_count = scene_frame_counts[0]
    print(f"âœ… é¸æ“‡æœ€ä½³å ´æ™¯: {best_scene.name} ({best_count} frames)")
    
    # é¡¯ç¤º top 5
    print(f"\nğŸ“Š Top 5 å ´æ™¯:")
    for scene_dir, frame_count in scene_frame_counts[:5]:
        marker = "â†’" if scene_dir == best_scene else " "
        print(f"   {marker} {scene_dir.name}: {frame_count} frames")
    
    return str(best_scene)


def load_frames(scene_dir, max_frames=40):
    """
    è¼‰å…¥å ´æ™¯å¹€
    
    æ”¯æ´:
    1. åœ–åƒç›®éŒ„ (jpg, png, jpeg)
    2. å½±ç‰‡æª”æ¡ˆ (mp4, avi, mov, mkv)
    """
    # æª¢æŸ¥æ˜¯å¦ç‚ºå½±ç‰‡æª”æ¡ˆ
    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm']
    if os.path.isfile(scene_dir) and any(scene_dir.lower().endswith(ext) for ext in video_extensions):
        return load_frames_from_video(scene_dir, max_frames)
    
    # åœ–åƒç›®éŒ„æ¨¡å¼
    patterns = [
        f'{scene_dir}/frame-*-color.render.jpg',
        f'{scene_dir}/frame-*.jpg',
        f'{scene_dir}/frame-*.png',
        f'{scene_dir}/*.jpg',
        f'{scene_dir}/*.jpeg',
        f'{scene_dir}/*.png',
        f'{scene_dir}/color/*.jpg',
        f'{scene_dir}/color/*.png',
        f'{scene_dir}/images/*.jpg',
        f'{scene_dir}/images/*.png',
    ]
    
    print(f"   æœå°‹ç›®éŒ„: {scene_dir}")
    print(f"   ç›®éŒ„æ˜¯å¦å­˜åœ¨: {os.path.exists(scene_dir)}")
    
    for pattern in patterns:
        files = sorted(glob.glob(pattern))
        if len(files) >= 5:
            print(f"   âœ… æ‰¾åˆ° {len(files)} å€‹åœ–åƒæ–‡ä»¶")
            return files[:max_frames]
    
    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œåˆ—å‡ºç›®éŒ„å…§å®¹
    print(f"   æ‰¾ä¸åˆ°è¶³å¤ çš„å¹€ï¼Œç›®éŒ„å…§å®¹:")
    if os.path.exists(scene_dir):
        for item in os.listdir(scene_dir)[:20]:
            print(f"      {item}")
    else:
        print(f"   ç›®éŒ„ä¸å­˜åœ¨: {scene_dir}")
    
    return []


def load_frames_from_video(video_path, max_frames=40, sample_fps=2):
    """
    å¾å½±ç‰‡æª”æ¡ˆè¼‰å…¥å¹€
    
    Args:
        video_path: å½±ç‰‡æª”æ¡ˆè·¯å¾‘
        max_frames: æœ€å¤§å¹€æ•¸
        sample_fps: æ¡æ¨£é »ç‡ï¼ˆæ¯ç§’å–å¹¾å¹€ï¼‰
    
    Returns:
        frames: å¹€è·¯å¾‘åˆ—è¡¨ï¼ˆè‡¨æ™‚ä¿å­˜çš„åœ–åƒï¼‰
    """
    import tempfile
    
    print(f"   ğŸ“¹ è¼‰å…¥å½±ç‰‡: {video_path}")
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"   âŒ ç„¡æ³•é–‹å•Ÿå½±ç‰‡: {video_path}")
        return []
    
    # å–å¾—å½±ç‰‡è³‡è¨Š
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = total_frames / fps if fps > 0 else 0
    
    print(f"   å½±ç‰‡è³‡è¨Š: {total_frames} å¹€, {fps:.1f} FPS, {duration:.1f} ç§’")
    
    # è¨ˆç®—æ¡æ¨£é–“éš”
    sample_interval = max(1, int(fps / sample_fps))
    
    # å»ºç«‹è‡¨æ™‚ç›®éŒ„å„²å­˜å¹€
    temp_dir = tempfile.mkdtemp(prefix='video_frames_')
    print(f"   è‡¨æ™‚ç›®éŒ„: {temp_dir}")
    
    frame_paths = []
    frame_idx = 0
    saved_count = 0
    
    while saved_count < max_frames:
        ret, frame = cap.read()
        if not ret:
            break
        
        # æ¡æ¨£
        if frame_idx % sample_interval == 0:
            frame_path = os.path.join(temp_dir, f'frame_{saved_count:04d}.jpg')
            cv2.imwrite(frame_path, frame)
            frame_paths.append(frame_path)
            saved_count += 1
        
        frame_idx += 1
    
    cap.release()
    print(f"   âœ… å¾å½±ç‰‡æå– {len(frame_paths)} å¹€")
    
    return frame_paths


def main():
    parser = argparse.ArgumentParser(description='Test Adaptive Memory Injection')
    parser.add_argument('--model_path', type=str, default=None, help='UnifiedTempoVLM æ¨¡å‹è·¯å¾‘')
    parser.add_argument('--scene_dir', type=str, default=None, 
                       help='å ´æ™¯ç›®éŒ„æˆ–å½±ç‰‡æª”æ¡ˆè·¯å¾‘ (æ”¯æ´ mp4/avi/mov/mkv)')
    parser.add_argument('--video', type=str, default=None,
                       help='å½±ç‰‡æª”æ¡ˆè·¯å¾‘ (èˆ‡ --scene_dir ç›¸åŒåŠŸèƒ½)')
    parser.add_argument('--data_root', type=str, default=None,
                       help='ScanNet è³‡æ–™æ ¹ç›®éŒ„ï¼ˆç”¨æ–¼è‡ªå‹•é¸æ“‡æœ€ä½³å ´æ™¯ï¼‰')
    parser.add_argument('--split', type=str, default='test', choices=['test', 'train'],
                       help='ä½¿ç”¨ test æˆ– train è³‡æ–™é›†')
    parser.add_argument('--auto_best', action='store_true',
                       help='è‡ªå‹•é¸æ“‡ frame æ•¸æœ€å¤šçš„å ´æ™¯')
    parser.add_argument('--max_frames', type=int, default=40, help='æœ€å¤§è™•ç†å¹€æ•¸')
    parser.add_argument('--sample_fps', type=float, default=2, help='å½±ç‰‡æ¡æ¨£é »ç‡ (æ¯ç§’å–å¹¾å¹€)')
    parser.add_argument('--add_occlusion', action='store_true', help='äººå·¥åŠ å…¥é®æ“‹')
    parser.add_argument('--occlusion_start', type=int, default=15)
    parser.add_argument('--occlusion_end', type=int, default=25)
    parser.add_argument('--occlusion_ratio', type=float, default=0.4)
    parser.add_argument('--occlusion_type', type=str, default='black',
                       choices=['black', 'white', 'noise', 'blur', 'color'],
                       help='é®æ“‹é¡å‹: black/white/noise/blur/color')
    parser.add_argument('--injection_method', type=str, default='full',
                       choices=['raw', 'full', 'strong', 'adaptive'],
                       help='æ³¨å…¥æ–¹æ³•: raw(ä¿å®ˆ)/full(å…¨åœ–)/strong(å¼·åŠ›ä¸­å¿ƒ)/adaptive(è‡ªé©æ‡‰)')
    parser.add_argument('--memory_size', type=int, default=8, help='è¨˜æ†¶åº«å¤§å°')
    parser.add_argument('--anomaly_threshold', type=float, default=0.25)
    parser.add_argument('--save_results', type=str, default=None, help='å„²å­˜çµæœåˆ°æŒ‡å®šç›®éŒ„')
    parser.add_argument('--no_log', action='store_true', help='ä¸è¨˜éŒ„æ—¥èªŒ')
    args = parser.parse_args()
    
    # è¨­å®šæ—¥èªŒè¨˜éŒ„
    logger = None
    log_path = None
    if not args.no_log:
        logger, log_path = setup_logging(args)
    
    results = []
    final_status = {'size': 0}
    
    try:
        _run_experiment(args, results, final_status)
    except Exception as e:
        print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ä¿å­˜å¯¦é©—æ‘˜è¦ä¸¦é—œé–‰æ—¥èªŒ
        if logger and log_path:
            try:
                if results:  # åªåœ¨æœ‰çµæœæ™‚ä¿å­˜
                    save_experiment_summary('logs', log_path, args, results, final_status)
            except Exception as e:
                print(f"âš ï¸ ä¿å­˜æ‘˜è¦å¤±æ•—: {e}")
            
            # é—œé–‰ loggerï¼Œæ¢å¾©æ¨™æº–è¼¸å‡º
            sys.stdout = logger.terminal
            logger.close()
            print(f"\nâœ… å¯¦é©—å®Œæˆï¼æ—¥èªŒå·²ä¿å­˜åˆ°: {log_path}")


def _run_experiment(args, results, final_status_ref):
    """å¯¦éš›åŸ·è¡Œå¯¦é©—çš„å…§éƒ¨å‡½æ•¸"""
    print("=" * 70)
    print("ğŸ§  Adaptive Memory Injection æ¸¬è©¦")
    print("=" * 70)
    print("\né€™å€‹æ¨¡å¼è‡ªå‹•ï¼š")
    print("  1. å»ºç«‹é«˜å“è³ªå¹€çš„è¨˜æ†¶åº«")
    print("  2. æª¢æ¸¬ç•°å¸¸/é®æ“‹å¹€")
    print("  3. å‹•æ…‹æ³¨å…¥è¨˜æ†¶ç‰¹å¾µ")
    
    # åˆå§‹åŒ–
    model_path = args.model_path or find_model_path()
    tester = OcclusionTester(unified_model_path=model_path)
    
    # å ´æ™¯æˆ–å½±ç‰‡ - æ”¯æ´è‡ªå‹•é¸æ“‡æœ€ä½³å ´æ™¯
    input_path = args.video or args.scene_dir
    
    # å¦‚æœå•Ÿç”¨ auto_best ä¸”æœ‰ data_rootï¼Œè‡ªå‹•é¸æ“‡æœ€ä½³å ´æ™¯
    if args.auto_best and args.data_root:
        print(f"\nğŸ” è‡ªå‹•å°‹æ‰¾æœ€ä½³å ´æ™¯ (frame æ•¸æœ€å¤š)...")
        input_path = find_best_scene(args.data_root, split=args.split, min_frames=args.max_frames)
    
    # å¦‚æœé‚„æ˜¯æ²’æœ‰æŒ‡å®šï¼Œä½¿ç”¨é è¨­æœå°‹
    if not input_path:
        input_path = find_scene_dir()
    
    if not input_path:
        print("âŒ è«‹æŒ‡å®šå ´æ™¯ç›®éŒ„æˆ–å½±ç‰‡æª”æ¡ˆ")
        print("   ä½¿ç”¨æ–¹å¼:")
        print("   python test_adaptive.py --scene_dir /path/to/images/")
        print("   python test_adaptive.py --video /path/to/video.mp4")
        print("   python test_adaptive.py --data_root /path/to/scannet --auto_best")
        return
    
    # è¼‰å…¥å¹€
    frame_files = load_frames(input_path, max_frames=args.max_frames)
    if len(frame_files) < 5:
        print(f"âŒ å¹€æ•¸ä¸è¶³ (éœ€è¦ >= 5, æ‰¾åˆ° {len(frame_files)})")
        return
    
    print(f"\nâœ… è¼‰å…¥ {len(frame_files)} å¹€ from {input_path}")
    
    if args.add_occlusion:
        print(f"ğŸ”² äººå·¥é®æ“‹: Frame {args.occlusion_start}-{args.occlusion_end}")
    
    # åˆå§‹åŒ–è¨˜æ†¶ç·©è¡å€
    memory_buffer = AdaptiveMemoryBuffer(
        max_size=args.memory_size,
        anomaly_threshold=args.anomaly_threshold
    )
    
    # æ¸…ç©ºæ™‚åºç·©è¡å€ï¼ˆæ–°å ´æ™¯ï¼‰
    if hasattr(tester, 'clear_temporal_buffer'):
        tester.clear_temporal_buffer()
        print("ğŸ”„ æ™‚åºç·©è¡å€å·²æ¸…ç©º")
    
    # é¡¯ç¤ºæ˜¯å¦ä½¿ç”¨ Adapter
    if tester.unified_model is not None:
        print("ğŸ§  Adapter æ™‚åºå¢å¼·: å•Ÿç”¨")
    else:
        print("âš ï¸ Adapter æ™‚åºå¢å¼·: æœªå•Ÿç”¨ (ä½¿ç”¨åŸå§‹ VLM ç‰¹å¾µ)")
    
    print("\n" + "=" * 70)
    print("ğŸ“Š é€å¹€è™•ç†")
    print("=" * 70)
    
    results = []
    
    for i, frame_file in enumerate(frame_files):
        original_img = Image.open(frame_file).convert('RGB')
        original_cv = cv2.cvtColor(np.array(original_img), cv2.COLOR_RGB2BGR)
        
        # æ˜¯å¦åŠ å…¥äººå·¥é®æ“‹
        is_artificial = False
        if args.add_occlusion and args.occlusion_start <= i < args.occlusion_end:
            h, w = original_cv.shape[:2]
            cx, cy = w // 2, h // 2
            size = int(min(w, h) * args.occlusion_ratio / 2)
            
            # æ ¹æ“šé®æ“‹é¡å‹æ‡‰ç”¨ä¸åŒçš„é®æ“‹
            occ_type = args.occlusion_type
            if occ_type == 'black':
                # é»‘è‰²æ–¹å¡Š
                cv2.rectangle(original_cv, (cx-size, cy-size), (cx+size, cy+size), (0, 0, 0), -1)
            elif occ_type == 'white':
                # ç™½è‰²æ–¹å¡Š
                cv2.rectangle(original_cv, (cx-size, cy-size), (cx+size, cy+size), (255, 255, 255), -1)
            elif occ_type == 'noise':
                # éš¨æ©Ÿå™ªè²
                noise = np.random.randint(0, 255, (size*2, size*2, 3), dtype=np.uint8)
                original_cv[cy-size:cy+size, cx-size:cx+size] = noise
            elif occ_type == 'blur':
                # é«˜æ–¯æ¨¡ç³Š
                roi = original_cv[cy-size:cy+size, cx-size:cx+size]
                blurred = cv2.GaussianBlur(roi, (99, 99), 0)
                original_cv[cy-size:cy+size, cx-size:cx+size] = blurred
            elif occ_type == 'color':
                # éš¨æ©Ÿç´”è‰²æ–¹å¡Š
                random_color = tuple(np.random.randint(0, 255, 3).tolist())
                cv2.rectangle(original_cv, (cx-size, cy-size), (cx+size, cy+size), random_color, -1)
            
            input_img = Image.fromarray(cv2.cvtColor(original_cv, cv2.COLOR_BGR2RGB))
            is_artificial = True
            if i == args.occlusion_start:
                print(f"   ğŸ”² é®æ“‹å·²å¥—ç”¨: Frame {args.occlusion_start}-{args.occlusion_end-1}, type={occ_type}, ratio={args.occlusion_ratio}")
        else:
            input_img = original_img
        
        # æå–ç‰¹å¾µ
        feat = tester.extract_features(input_img)
        adapter_meta = getattr(tester, 'last_adapter_meta', None)
        
        # å˜—è©¦åŠ å…¥è¨˜æ†¶åº«
        result = memory_buffer.add_frame(feat, i, input_img, adapter_meta=adapter_meta)
        if len(result) == 5:
            added, quality, anomaly_score, is_anomaly, debug_info = result
        else:
            added, quality, anomaly_score, is_anomaly = result
            debug_info = {'image_occlusion': 0.0}
        
        img_occ = debug_info.get('image_occlusion', 0.0)
        
        # å¦‚æœç•°å¸¸ï¼Œå˜—è©¦æ³¨å…¥
        injection_result = None
        gt_response = None  # Ground Truth å›æ‡‰
        occluded_response = None  # é®æ“‹åœ–åƒçš„ç›´æ¥å›æ‡‰ï¼ˆç„¡æ³¨å…¥ï¼‰
        
        if is_anomaly and len(memory_buffer.features) > 0:
            # === æ–°å¢ï¼šæå–é‚Šç·£ç‰¹å¾µç”¨æ–¼å ´æ™¯è®ŠåŒ–æª¢æ¸¬ ===
            edge_feat = None
            try:
                edge_feat = tester.extract_edge_features(input_img)
            except Exception as e:
                pass  # å¦‚æœå¤±æ•—ï¼Œç¹¼çºŒä½¿ç”¨ None
            
            # ä½¿ç”¨é‚Šç·£ç‰¹å¾µé¸æ“‡æœ€ä½³è¨˜æ†¶
            best_memory, score, info = memory_buffer.get_best_memory(feat, i, edge_feat=edge_feat)
            
            if best_memory is not None:
                # å–å¾—å ´æ™¯åŒ¹é…åº¦èˆ‡ Adapter å¯é åº¦
                scene_match = info.get('scene_match', 1.0)
                adapter_reliability = 1.0
                if info.get('adapter_meta'):
                    mq = info['adapter_meta'].get('memory_quality')
                    if mq is not None:
                        adapter_reliability = max(0.0, min(1.0, float(mq)))
                
                # å‚³é scene_match ä»¥å‹•æ…‹èª¿æ•´æ³¨å…¥å¼·åº¦
                base_strength = memory_buffer.compute_injection_strength(
                    anomaly_score, score, 
                    image_occlusion=img_occ,
                    scene_match=scene_match,
                    memory_reliability=adapter_reliability
                )
                
                # === å¼·åº¦é™åˆ¶ï¼ˆæ”¾å¯¬ä¸Šé™ï¼Œä¸­å¿ƒé®ç½©å·²é™ä½é¢¨éšªï¼‰===
                if args.injection_method == 'full':
                    # full åƒ…ä½œç”¨ä¸­å¿ƒé®ç½©ï¼Œå…è¨±æ›´é«˜ä¸Šé™
                    strength = min(0.35, base_strength * 0.8)
                elif args.injection_method in ('adaptive', 'strong'):
                    strength = min(0.40, base_strength * 0.9)
                else:  # raw
                    strength = min(0.45, base_strength)
                
                prompt = "Describe what you see in the center of this image."
                
                try:
                    # === 1. æ³¨å…¥å¾Œçš„å›æ‡‰ ===
                    response = tester.generate_with_direct_injection(
                        current_image=input_img,
                        enhanced_feat=best_memory,
                        prompt=prompt,
                        injection_method=args.injection_method,
                        injection_strength=strength
                    )
                    
                    # === 2. Ground Truthï¼šå°åŸå§‹åœ–åƒï¼ˆç„¡é®æ“‹ï¼‰ç”Ÿæˆæè¿° ===
                    gt_response = tester.generate_description(original_img, prompt)
                    
                    # === 3. é®æ“‹åœ–åƒçš„ç›´æ¥å›æ‡‰ï¼ˆç„¡æ³¨å…¥ï¼Œç”¨æ–¼å°æ¯”ï¼‰===
                    occluded_response = tester.generate_description(input_img, prompt)
                    
                    injection_result = {
                        'response': response,
                        'strength': strength,
                        'memory_frame': info['timestamp'],
                        'memory_score': score,
                        'scene_match': scene_match,
                        'memory_quality': adapter_reliability,
                        'gt_response': gt_response,
                        'occluded_response': occluded_response
                    }
                except Exception as e:
                    injection_result = {'error': str(e)}
        
        results.append({
            'frame': i,
            'quality': quality,
            'anomaly_score': anomaly_score,
            'image_occlusion': img_occ,
            'is_anomaly': is_anomaly,
            'added': added,
            'artificial': is_artificial,
            'injection': injection_result
        })
        
        # æ‰“å°ï¼ˆåŒ…å«åœ–åƒé®æ“‹åˆ†æ•¸ï¼‰
        icon = "âš ï¸" if is_anomaly else ("âœ…" if added else "â–")
        status = memory_buffer.get_status()
        occ_mark = "[OCC]" if is_artificial else "     "
        
        print(f"\n  Frame {i:2d}: {occ_mark} {icon} q={quality:.2f} a={anomaly_score:.2f} img={img_occ:.2f} mem={status['size']}", end="")
        
        if is_anomaly and injection_result:
            if 'response' in injection_result:
                resp = injection_result['response']
                gt_resp = injection_result.get('gt_response', '')
                occ_resp = injection_result.get('occluded_response', '')
                scene_match = injection_result.get('scene_match', 1.0)
                
                # é¡¯ç¤ºå ´æ™¯åŒ¹é…åº¦
                scene_indicator = "ğŸ”´" if scene_match < 0.5 else ("ğŸŸ¡" if scene_match < 0.7 else "ğŸŸ¢")
                print(f" â†’ æ³¨å…¥ (s={injection_result['strength']:.2f}, F{injection_result['memory_frame']}, {scene_indicator}match={scene_match:.2f})")
                
                # === ä½¿ç”¨ print_response é¡¯ç¤ºä¸‰ç¨®å›æ‡‰ ===
                # çµ‚ç«¯æˆªæ–·é¡¯ç¤ºï¼Œæª”æ¡ˆä¿å­˜å®Œæ•´å…§å®¹
                print_response("â”Œâ”€ ğŸ¯ GT (åŸåœ–):", gt_resp, max_terminal_lines=3)
                print_response("â”œâ”€ âŒ é®æ“‹ (ç„¡æ³¨å…¥):", occ_resp, max_terminal_lines=3)
                print_response("â””â”€ ğŸ’‰ æ³¨å…¥å¾Œ:", resp, max_terminal_lines=3)
                    
            elif 'error' in injection_result:
                print(f" â†’ æ³¨å…¥å¤±æ•—: {injection_result['error'][:50]}")
            else:
                print(f" â†’ æ³¨å…¥ (ç„¡å›æ‡‰)")
        else:
            print()
    
    # ç¸½çµ
    print("\n" + "=" * 70)
    print("ğŸ“Š ç¸½çµ")
    print("=" * 70)
    
    anomalies = [r for r in results if r['is_anomaly']]
    injected = [r for r in results if r['injection'] and 'response' in r.get('injection', {})]
    
    print(f"\nç¸½å¹€æ•¸: {len(results)}")
    print(f"æª¢æ¸¬åˆ°ç•°å¸¸: {len(anomalies)}")
    print(f"æˆåŠŸæ³¨å…¥: {len(injected)}")
    
    final_status = memory_buffer.get_status()
    print(f"è¨˜æ†¶åº«å¤§å°: {final_status['size']}")
    
    if 'zscore_stats' in final_status:
        zs = final_status['zscore_stats']
        print(f"\nğŸ“ˆ Z-Score çµ±è¨ˆ:")
        print(f"   æ­·å²æ¨£æœ¬æ•¸: {zs['history_size']}")
        print(f"   ç•°å¸¸åˆ†æ•¸ Î¼: {zs['anomaly_mu']:.4f}")
        print(f"   ç•°å¸¸åˆ†æ•¸ Ïƒ: {zs['anomaly_sigma']:.4f}")
        print(f"   å‹•æ…‹é–¾å€¼: {zs['dynamic_threshold']:.4f}")
    
    if args.add_occlusion:
        artificial = [r for r in results if r['artificial']]
        detected = [r for r in artificial if r['is_anomaly']]
        
        non_occluded = [r for r in results if not r['artificial']]
        false_positives = [r for r in non_occluded if r['is_anomaly']]
        
        print(f"\nğŸ¯ æª¢æ¸¬çµæœ:")
        print(f"   äººå·¥é®æ“‹: {len(artificial)} å¹€")
        print(f"   æª¢æ¸¬æˆåŠŸ: {len(detected)} ({len(detected)/max(len(artificial),1)*100:.1f}%)")
        print(f"   èª¤å ±æ•¸: {len(false_positives)} ({len(false_positives)/max(len(non_occluded),1)*100:.1f}%)")
        
        # === è©³ç´°å°æ¯”åˆ†æ ===
        print(f"\n" + "=" * 70)
        print("ğŸ“ è©³ç´°å°æ¯”åˆ†æ")
        print("=" * 70)
        
        for r in results:
            if r['injection'] and 'response' in r['injection']:
                inj = r['injection']
                print(f"\nğŸ“ Frame {r['frame']} (é®æ“‹ç‡: {r['image_occlusion']:.2f})")
                print(f"   æ³¨å…¥å¼·åº¦: {inj['strength']:.2f}, è¨˜æ†¶ä¾†æº: F{inj['memory_frame']}")
                print(f"   å ´æ™¯åŒ¹é…: {inj.get('scene_match', 1.0):.2f}")
                
                # ä½¿ç”¨ print_response é¡¯ç¤ºå®Œæ•´å…§å®¹åˆ°æª”æ¡ˆ
                gt = inj.get('gt_response', '(ç„¡)')
                occ = inj.get('occluded_response', '(ç„¡)')
                resp = inj.get('response', '(ç„¡)')
                
                print_response(" Ground Truth (åŸåœ–):", gt, max_terminal_lines=5)
                print_response(" é®æ“‹åœ– (ç„¡æ³¨å…¥):", occ, max_terminal_lines=5)
                print_response(" æ³¨å…¥å¾Œ:", resp, max_terminal_lines=5)
                print("-" * 70)
    
    final_status_ref.update(final_status)


if __name__ == '__main__':
    main()
